{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customer churn model training for customer retention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following process will compare customer churn prediction based on a simple Neural Network (Deep Learning) approach compared to tradition ML approaches. While Deep Learning is the buzz word in AI circles these days, that does not mean it will always outperform tradition ML methods - particularly when run on tabluar data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df = pd.read_csv('Telco-Customer-Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
       "3  7795-CFOCW    Male              0      No         No      45           No   \n",
       "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
       "0  No phone service             DSL             No  ...               No   \n",
       "1                No             DSL            Yes  ...              Yes   \n",
       "2                No             DSL            Yes  ...               No   \n",
       "3  No phone service             DSL            Yes  ...              Yes   \n",
       "4                No     Fiber optic             No  ...               No   \n",
       "\n",
       "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
       "0          No          No              No  Month-to-month              Yes   \n",
       "1          No          No              No        One year               No   \n",
       "2          No          No              No  Month-to-month              Yes   \n",
       "3         Yes          No              No        One year               No   \n",
       "4          No          No              No  Month-to-month              Yes   \n",
       "\n",
       "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
       "0           Electronic check          29.85         29.85    No  \n",
       "1               Mailed check          56.95        1889.5    No  \n",
       "2               Mailed check          53.85        108.15   Yes  \n",
       "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
       "4           Electronic check          70.70        151.65   Yes  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning and test-train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up X and y variables from dataset\n",
    "X = pd.get_dummies(churn_df.drop(['customerID', 'Churn'], axis = 1))\n",
    "y = churn_df.Churn.apply(lambda x : 1 if x=='Yes' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - Simple Neural Network (Deep Learning) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Deep Learning Model Dependencies\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a base 2 layer model of 32, and 64 neurons\n",
    "model = Sequential()\n",
    "model.add(Dense(units=32, activation='relu', input_dim=len(X_train.columns)))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.5112 - accuracy: 0.7399 - val_loss: 1.7633 - val_accuracy: 0.2640\n",
      "Epoch 2/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7486 - val_loss: 0.4763 - val_accuracy: 0.7864\n",
      "Epoch 3/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.7673 - val_loss: 0.4720 - val_accuracy: 0.7857\n",
      "Epoch 4/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.7666 - val_loss: 0.4683 - val_accuracy: 0.7864\n",
      "Epoch 5/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.7671 - val_loss: 0.5514 - val_accuracy: 0.7360\n",
      "Epoch 6/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7716 - val_loss: 0.5591 - val_accuracy: 0.7360\n",
      "Epoch 7/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.7768 - val_loss: 0.4911 - val_accuracy: 0.7693\n",
      "Epoch 8/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4727 - accuracy: 0.7785 - val_loss: 0.9101 - val_accuracy: 0.7360\n",
      "Epoch 9/100\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.4827 - accuracy: 0.7699 - val_loss: 0.5973 - val_accuracy: 0.7360\n",
      "Epoch 10/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.7754 - val_loss: 0.5464 - val_accuracy: 0.7360\n",
      "Epoch 11/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.7761 - val_loss: 0.5510 - val_accuracy: 0.7360\n",
      "Epoch 12/100\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7718 - val_loss: 0.6258 - val_accuracy: 0.6891\n",
      "Epoch 13/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.7735 - val_loss: 0.7010 - val_accuracy: 0.6494\n",
      "Epoch 14/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.7754 - val_loss: 1.5119 - val_accuracy: 0.4556\n",
      "Epoch 15/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.7728 - val_loss: 0.5485 - val_accuracy: 0.7360\n",
      "Epoch 16/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7778 - val_loss: 0.4792 - val_accuracy: 0.7672\n",
      "Epoch 17/100\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7794 - val_loss: 0.4501 - val_accuracy: 0.7942\n",
      "Epoch 18/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7773 - val_loss: 0.7620 - val_accuracy: 0.6125\n",
      "Epoch 19/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7711 - val_loss: 0.5179 - val_accuracy: 0.7665\n",
      "Epoch 20/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7813 - val_loss: 0.4803 - val_accuracy: 0.7729\n",
      "Epoch 21/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7834 - val_loss: 0.4498 - val_accuracy: 0.7899\n",
      "Epoch 22/100\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7851 - val_loss: 0.4708 - val_accuracy: 0.7693\n",
      "Epoch 23/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7806 - val_loss: 0.7132 - val_accuracy: 0.7360\n",
      "Epoch 24/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7832 - val_loss: 0.4567 - val_accuracy: 0.7807\n",
      "Epoch 25/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7811 - val_loss: 0.6056 - val_accuracy: 0.7360\n",
      "Epoch 26/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7782 - val_loss: 0.4540 - val_accuracy: 0.7949\n",
      "Epoch 27/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7839 - val_loss: 0.4642 - val_accuracy: 0.7842\n",
      "Epoch 28/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7818 - val_loss: 0.4668 - val_accuracy: 0.7516\n",
      "Epoch 29/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7820 - val_loss: 0.5367 - val_accuracy: 0.7466\n",
      "Epoch 30/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.7804 - val_loss: 0.5059 - val_accuracy: 0.7587\n",
      "Epoch 31/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.7806 - val_loss: 0.5218 - val_accuracy: 0.7360\n",
      "Epoch 32/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.7870 - val_loss: 0.4914 - val_accuracy: 0.7835\n",
      "Epoch 33/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.7815 - val_loss: 0.4545 - val_accuracy: 0.7764\n",
      "Epoch 34/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7794 - val_loss: 0.4462 - val_accuracy: 0.7878\n",
      "Epoch 35/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.7832 - val_loss: 1.4037 - val_accuracy: 0.4684\n",
      "Epoch 36/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.7704 - val_loss: 0.4531 - val_accuracy: 0.7850\n",
      "Epoch 37/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7832 - val_loss: 0.5536 - val_accuracy: 0.7410\n",
      "Epoch 38/100\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7822 - val_loss: 0.4516 - val_accuracy: 0.7835\n",
      "Epoch 39/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.4566 - accuracy: 0.7860 - val_loss: 0.6408 - val_accuracy: 0.6167\n",
      "Epoch 40/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7818 - val_loss: 0.8865 - val_accuracy: 0.5330\n",
      "Epoch 41/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.4623 - accuracy: 0.7773 - val_loss: 0.4649 - val_accuracy: 0.7899\n",
      "Epoch 42/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.4563 - accuracy: 0.7799 - val_loss: 0.6390 - val_accuracy: 0.6657\n",
      "Epoch 43/100\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7763 - val_loss: 0.4481 - val_accuracy: 0.7878\n",
      "Epoch 44/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.7775 - val_loss: 0.4448 - val_accuracy: 0.7928\n",
      "Epoch 45/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.7799 - val_loss: 0.5601 - val_accuracy: 0.7495\n",
      "Epoch 46/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.7792 - val_loss: 0.4765 - val_accuracy: 0.7700\n",
      "Epoch 47/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.7815 - val_loss: 1.5810 - val_accuracy: 0.4748\n",
      "Epoch 48/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7801 - val_loss: 0.4451 - val_accuracy: 0.7949\n",
      "Epoch 49/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7891 - val_loss: 0.4786 - val_accuracy: 0.7736\n",
      "Epoch 50/100\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.4513 - accuracy: 0.78 - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7884 - val_loss: 0.5322 - val_accuracy: 0.7644\n",
      "Epoch 51/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.7834 - val_loss: 0.4765 - val_accuracy: 0.7786\n",
      "Epoch 52/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7825 - val_loss: 0.5940 - val_accuracy: 0.7381\n",
      "Epoch 53/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7867 - val_loss: 0.5688 - val_accuracy: 0.7644\n",
      "Epoch 54/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.7860 - val_loss: 0.7294 - val_accuracy: 0.7360\n",
      "Epoch 55/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.7846 - val_loss: 0.5922 - val_accuracy: 0.7360\n",
      "Epoch 56/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7775 - val_loss: 0.4860 - val_accuracy: 0.7835\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4556 - accuracy: 0.7792 - val_loss: 0.5855 - val_accuracy: 0.6998\n",
      "Epoch 58/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7799 - val_loss: 0.8914 - val_accuracy: 0.7360\n",
      "Epoch 59/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7818 - val_loss: 0.7071 - val_accuracy: 0.7360\n",
      "Epoch 60/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7867 - val_loss: 0.4408 - val_accuracy: 0.7942\n",
      "Epoch 61/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7841 - val_loss: 0.5262 - val_accuracy: 0.7360\n",
      "Epoch 62/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7844 - val_loss: 0.7949 - val_accuracy: 0.7360\n",
      "Epoch 63/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.7837 - val_loss: 0.4460 - val_accuracy: 0.7771\n",
      "Epoch 64/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7851 - val_loss: 0.4372 - val_accuracy: 0.7928\n",
      "Epoch 65/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7801 - val_loss: 0.5311 - val_accuracy: 0.7360\n",
      "Epoch 66/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7773 - val_loss: 0.4603 - val_accuracy: 0.7850\n",
      "Epoch 67/100\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7832 - val_loss: 0.4516 - val_accuracy: 0.7857\n",
      "Epoch 68/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.7830 - val_loss: 0.6412 - val_accuracy: 0.6537\n",
      "Epoch 69/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.7749 - val_loss: 0.4773 - val_accuracy: 0.7445\n",
      "Epoch 70/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7867 - val_loss: 0.4652 - val_accuracy: 0.7828\n",
      "Epoch 71/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7920 - val_loss: 0.4742 - val_accuracy: 0.7722\n",
      "Epoch 72/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7865 - val_loss: 0.4550 - val_accuracy: 0.7793\n",
      "Epoch 73/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7841 - val_loss: 0.6030 - val_accuracy: 0.6700\n",
      "Epoch 74/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.7870 - val_loss: 0.5997 - val_accuracy: 0.7360\n",
      "Epoch 75/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4468 - accuracy: 0.7870 - val_loss: 1.4453 - val_accuracy: 0.4975\n",
      "Epoch 76/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7796 - val_loss: 0.5959 - val_accuracy: 0.7048\n",
      "Epoch 77/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.7896 - val_loss: 0.4471 - val_accuracy: 0.7935\n",
      "Epoch 78/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.7860 - val_loss: 0.5053 - val_accuracy: 0.7360\n",
      "Epoch 79/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7815 - val_loss: 0.7243 - val_accuracy: 0.6260\n",
      "Epoch 80/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7804 - val_loss: 0.6026 - val_accuracy: 0.6849\n",
      "Epoch 81/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7891 - val_loss: 0.5179 - val_accuracy: 0.7480\n",
      "Epoch 82/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7912 - val_loss: 0.5016 - val_accuracy: 0.7353\n",
      "Epoch 83/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7825 - val_loss: 0.4375 - val_accuracy: 0.7970\n",
      "Epoch 84/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7905 - val_loss: 0.4334 - val_accuracy: 0.7977\n",
      "Epoch 85/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7841 - val_loss: 0.6172 - val_accuracy: 0.7360\n",
      "Epoch 86/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.7877 - val_loss: 0.4691 - val_accuracy: 0.7665\n",
      "Epoch 87/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7898 - val_loss: 0.8261 - val_accuracy: 0.5940\n",
      "Epoch 88/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7818 - val_loss: 0.4531 - val_accuracy: 0.7892\n",
      "Epoch 89/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.7950 - val_loss: 1.1084 - val_accuracy: 0.5656\n",
      "Epoch 90/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7858 - val_loss: 0.4403 - val_accuracy: 0.7977\n",
      "Epoch 91/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7818 - val_loss: 0.4448 - val_accuracy: 0.7991\n",
      "Epoch 92/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7820 - val_loss: 0.4472 - val_accuracy: 0.7786\n",
      "Epoch 93/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7867 - val_loss: 0.4457 - val_accuracy: 0.7892\n",
      "Epoch 94/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7849 - val_loss: 0.8286 - val_accuracy: 0.7360\n",
      "Epoch 95/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.7896 - val_loss: 0.4379 - val_accuracy: 0.7977\n",
      "Epoch 96/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7837 - val_loss: 0.4320 - val_accuracy: 0.7984\n",
      "Epoch 97/100\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7896 - val_loss: 0.5852 - val_accuracy: 0.7360\n",
      "Epoch 98/100\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7910 - val_loss: 0.4844 - val_accuracy: 0.7601\n",
      "Epoch 99/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.7938 - val_loss: 0.4558 - val_accuracy: 0.7999\n",
      "Epoch 100/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7896 - val_loss: 0.5655 - val_accuracy: 0.7360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17d91a04b50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit to the data\n",
    "model.fit(X_train, y_train, validation_split=0.25, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "y_hat = model.predict(X_test)\n",
    "y_hat = [0 if val < 0.5 else 1 for val in y_hat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7487579843860894"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get accuracy metric\n",
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score seen here is 75% for it's predictions of customer churn on the test data. This is a reasonably accuracy given the difficulty of the dataset. While this model trains reasonably quickly, it is a bare-bones base model of only 2 layers without hyperparameter tuning, and data scaling. It could definitely be improved further through hyperparameter tuning, increasing the epochs, making a deeper layer neural network, or adding CNN layers etc.\n",
    "\n",
    "Nonetheless, it has produced a reasonable result considering to overall data.\n",
    "\n",
    "Now lets run a more standard LinearSVC and LogisticRegression for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC and LogisticRegression for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the difference in the TF neural network here vs other models, LinearSVC and LogisticRegression have been imported below for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7547035853745119\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Create LinearSVC model and train\n",
    "lsvc = LinearSVC(verbose=0)\n",
    "lsvc.fit(X_train, y_train)\n",
    "\n",
    "# Get test training score\n",
    "acc = lsvc.score(X_train, y_train)\n",
    "print(\"Accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite failing to converge, a simple LinearSVC classifier has performed to the same level as our base deep learning model. Results could easily be improved here by scaling the data beforehand and looking at other possible methods such as PCA.\n",
    "\n",
    "This shows a good example of how deep learning is not always the best answer in comparison to a simple algorithm which can perfomr similarly yet produce explainable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.99      0.86      1055\n",
      "           1       0.57      0.02      0.04       354\n",
      "\n",
      "    accuracy                           0.75      1409\n",
      "   macro avg       0.66      0.51      0.45      1409\n",
      "weighted avg       0.71      0.75      0.65      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict on test data\n",
    "lsvc_y_hat = lsvc.predict(X_test)\n",
    "\n",
    "# Generate classification report\n",
    "cr = classification_report(y_test, lsvc_y_hat)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(random_state=0, solver='lbfgs').fit(X_train, y_train)\n",
    "log_reg_y_hat = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8146964856230032"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get test training score\n",
    "log_reg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen here, the base LogisticRegression model, despite failing to converge, has outperformed the based deeplearing model with an accuracy of 81%. This again could easily be improved, but has at it's base, done a reasonable job and the best of the three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87      1055\n",
      "           1       0.63      0.57      0.60       354\n",
      "\n",
      "    accuracy                           0.81      1409\n",
      "   macro avg       0.75      0.73      0.74      1409\n",
      "weighted avg       0.80      0.81      0.81      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate classification report\n",
    "cr = classification_report(y_test, log_reg_y_hat)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, both of these model have performed at the standard of or outperformed the deep learning model. Taking an ensemble model such as RandomForestClassifier is likely to beat the model even further. So, as a final test, let's try it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9976925807596734\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfcl = RandomForestClassifier()\n",
    "rfcl.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Get test training score\n",
    "acc = rfcl.score(X_train, y_train)\n",
    "print(\"Accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87      1055\n",
      "           1       0.63      0.57      0.60       354\n",
      "\n",
      "    accuracy                           0.81      1409\n",
      "   macro avg       0.75      0.73      0.74      1409\n",
      "weighted avg       0.80      0.81      0.81      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfcl_y_hat = log_reg.predict(X_test)\n",
    "\n",
    "# Generate classification report\n",
    "cr = classification_report(y_test, rfcl_y_hat)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen our ensemble RandomForestClassifier, without any hyperparameter tuning, working on non-scaled data, has produced an accuracy of 99.7%. Massively outperforming our other classifiers as well as the deep learning model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While deep learning is often the go-to response and the buzzword in data science right now, it is not always the optimal choice for the problem at hand. Not only can it be outperformed by standard classifiers, but the results of the standard classifiers are explainable rather than black-box should you incur a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
